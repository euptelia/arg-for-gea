"""
Generate tables for neutral models to compare false positive rate of neutral alleles,
using tree sequences generated by CONTINUOUS SPACE nonWF models in SLiM
Updates compared to alleleAge.py:
    Does not calculate LFmut, but replace the LFmut column with average LF
    (one value per file)
    Add next_id = pyslim.next_slim_mutation_id(sts)
tianlin.duan42@gmail.com
2024.07.23
"""
############################# modules #########################################
import msprime
import tskit
# import pyslim
import matplotlib.pyplot as plt
import scipy.stats as stats
from scipy.spatial import distance_matrix
import numpy as np
# import pandas
import random
# from time import time
import sys # for sys.exit()
# import allel # for allel.weir_cockerham_fst()
import os # mkdir

# ############################# options #############################
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('-i', '--input',
                    help='Input .trees file with its absolute path',
                    type=str)
parser.add_argument('-p', '--plot',
                    help='1 for generating plots and 0 for not plotting',
                    type=int, default=1)
args = parser.parse_args()

############################# functions #######################################
def LF_fitness(ind_x, ind_y, phenotype,
               optima, dist_mate, sigma_w):
    """Takes x and y coordinates (array-like), phenotypes (array-like),
        environmental optima (array-like), a maximum distance for mating (single value),
        and a standard deviation of fitness function (single value).
    Return two arrays of the average fitness of local and foreign individuals,
     respectively.
    v2: time efficient but not memory efficient.
    Try the other version when the number of individuals is large.
    """
    optima=np.array(optima)
    coord = list(zip(ind_x, ind_y))
    dist_matrix = distance_matrix(coord, coord)
    isLocal_matrix = dist_matrix <= dist_mate
    # Calculate fitness matrix (w_matrix[i][j]: individual j at location i)
    # with broadcast
    w_matrix = 1.0 + stats.norm.pdf(np.array(phenotype),
                                    np.array(optima)[:, np.newaxis],
                                    sigma_w)
    # relative fitness
    w_matrix = w_matrix / np.mean(w_matrix, 1)[:, np.newaxis]
    #Average relative fitness of local and foreign individuals
    w_local = np.mean(np.ma.masked_array(w_matrix, np.invert(isLocal_matrix)),
                      1)
    w_foreign = np.mean(np.ma.masked_array(w_matrix, isLocal_matrix), 1)
    return w_local, w_foreign

############################# program #########################################
# Values
sigma_w = 0.4
# sigma_w = 1.0
# sigma_w = 2.0
dist_mate = 0.15
sample_size = 500

#User input arguments:
path_file_name = args.input
# path_file_name = "/home/tianlin/Documents/github/data/slim_data/glacial_history/realistic_fpr_comparisons/M0a_smallLowVm_lowMig_clineMap/tick110000/batch1/Continuous_nonWF_M0a_glacialHistoryOptimum0_clineMap_mu1.0e-08_sigmaM0.01_sigmaW0.4_sigmaD0.03_mateD0.12_K5000_r1.0e-07_seed22612012541755499_tick110000.trees"
# Remove paths
file_name = path_file_name.split("/")[-1]
model_name = file_name[0:-6]  # Assuming the file name extension is .trees
# Delete seed and tick information for making a directory
short_model_name = "_".join(file_name.split("_")[0:-2])

figPath = "/home/tianlin/Documents/github/data/tskit_data/figure/20240822/"
outBasePath = "/home/tianlin/Documents/github/data/tskit_data/output/table/realistic_fpr_comparisons/"
outPath = outBasePath+short_model_name+"/"
if not os.path.exists(outPath):
    os.makedirs(outPath)
if not os.path.exists(figPath):
    os.makedirs(figPath)

# current_tick = int(model_name.split("_")[-1][4:]) # hard coded for a specific name pattern, not ideal
history = 100000 # number of generations before the focal model

# Tree-sequence file from SLiM
ts = tskit.load(path_file_name)
current_tick = ts.metadata['SLiM']['tick']
ind_x, ind_y, ind_z = zip(*ts.individuals_location)
# Genomic position of sites
pos = ts.sites_position
# Genomic position of mutations
pos_by_mut = ts.sites_position[ts.mutations_site]
# Maximum tick
max_tick = ts.metadata["SLiM"]["tick"]
# Number of diploid individuals
N = ts.num_individuals
# Environmental optima
optima = np.array(ts.metadata['SLiM']['user_metadata']['indsOptimum'])
mapValues = np.array(ts.metadata['SLiM']['user_metadata']['mapValues'])

# Recapitation: skipped as no functional mutation was added during this stage
# ts_recap = pyslim.recapitate(ts, ancestral_Ne=5e3,
#                              recombination_rate=1e-7,
#                              random_seed=1)
#
# (tmrca_recap, kb_recap) = tree_heights(ts_recap)

# Add neutral mutations
mutation_seed = random.randint(1, 2**31)
mut_model1 = msprime.SLiMMutationModel(type=1)
mts = msprime.sim_mutations(ts,
                            rate=5e-8,
                            random_seed=mutation_seed,
                            model=mut_model1,
                            keep=True) #keep the existing mutations

# Phenotypic effect of each mutation
# 1-dimensional
mut_effect = []
for mut in mts.mutations():
    mut_effect.append(mut.metadata['mutation_list'][0]['selection_coeff'])
mut_effect = np.array(mut_effect)

# 2-dimensional: list of lists, corresponding to phenotypic effect of allele 0/1/2... at each site
mut_effect_lists = []
for site in mts.sites():
    effect_site = [0]
    for mut in site.mutations:
        effect_site.append(mut.metadata['mutation_list'][0]['selection_coeff'])
    mut_effect_lists.append(effect_site)

# Observed extent of local adaptation (local-foreign contrast (LF))
(w_local, w_foreign) = LF_fitness(ind_x, ind_y, ind_z,
                                  optima, dist_mate, sigma_w)
LF_cline = w_local - w_foreign
mean_LF = np.mean(LF_cline)
# Overall extent of local adaptation
#print(mean_LF)

# # Contribution of each mutation to LF
# # Version 2: randomizing the distribution of the mutation
# # Skip calculation for neutral mutations
# shuffle_replicates = 1
# LF_shuffle = []
# t = time()
# index_site = 0
# # traverse sites with mutations
# for v in mts.variants():
#     # Skip calculation and directly append mean_LF as LF_shuffle
#     # By definition neutral mutations should not affect phenotypes at all
#     if sum(mut_effect_lists[index_site]) == 0:
#         index_gt = 1
#         while index_gt < len(mut_effect_lists[index_site]):
#             LF_shuffle.append(mean_LF)
#             index_gt += 1
#     else:
#         # Calculate the effect of each mutation at the focal site
#         index_gt = 1
#         # traverse all derived alleles at the site
#         while index_gt < len(mut_effect_lists[index_site]):
#             # for multiallelic sites, hide other alleles at the site except the focal allele,
#             # leave only one allele at each time
#             focal_gt = np.array(v.genotypes)
#             focal_gt[focal_gt != index_gt] = 0
#             # effect of the focal mutation in each individual
#             effect_mut_genomes = np.array(mut_effect_lists[index_site])[focal_gt]
#             # Add up the two genomes of each individual
#             effect_mut_ind = (effect_mut_genomes[range(0, 2 * N - 1, 2)] +
#                               effect_mut_genomes[range(1, 2 * N, 2)])
#             phenotype_without_mut = ind_z - effect_mut_ind
#             # Shuffle the distribution of the individuals
#             # (without changing the observed heterozygosity)
#             r = 0
#             LF_shuffle_mut = np.zeros(shuffle_replicates)
#             while r < shuffle_replicates:
#                 effect_mut_ind_shuffle = list(effect_mut_ind)  # shallow copy
#                 np.random.shuffle(effect_mut_ind_shuffle)
#                 # print(list(effect_mut_ind))
#                 # print(effect_mut_ind_shuffle)
#                 # Phenotype with shuffled mut =
#                 # phenotypes of each ind - effect of the focal mutation in each ind
#                 # + effect of the focal mutation in each ind after shuffling
#                 phenotype_shuffle = phenotype_without_mut + effect_mut_ind_shuffle
#                 (w_local, w_foreign) = LF_fitness(ind_x, ind_y, phenotype_shuffle,
#                                                   optima, dist_mate, sigma_w)
#                 LF_shuffle_mut[r] = np.mean(w_local - w_foreign)
#                 r += 1
#             LF_shuffle.append(np.mean(LF_shuffle_mut))
#             index_gt += 1
#     index_site += 1
#     if index_site % 10000 == 0:
#         print(f"{index_site} sites processed")
# delta_LF_mut = mean_LF-LF_shuffle
# # Elapsed Time
# timer = time() - t
# print(timer/60)
# for 1 replicate, 373377 neutral sites and 200 functional sites take 4 minutes
# for 1 replicate, 333977 neutral sites and 200 functional sites take 28 minutes

# Age of each mutation
age = mts.mutations_time
pos_by_mut = mts.sites_position[mts.mutations_site]

# Mutation effects by mutation coordinates
effect_by_mut = []
for site in mts.sites():
    for mut in site.mutations:
        effect_by_mut.append(mut.metadata['mutation_list'][0]['selection_coeff'])
effect_by_mut = np.array(effect_by_mut)

# Frequency of each mutation
freq = []
num_samples = mts.num_samples
for v in mts.variants():
    for allele in np.arange(1, v.num_alleles):
        focal_freq = np.count_nonzero(v.genotypes == allele)/num_samples
        freq.append(focal_freq)
freq_segragate = [f for f in freq if (f != 0) & (f != 1)]

# # Test: Extract frequency for a realistic sample
# # Not used anymore as subsampling was moved to an earlier step
# freq_subsample = []
# num_samples = mts.num_samples
# for v in mts.variants(samples=samples_id):
#     for allele in np.arange(1, v.num_alleles):
#         focal_freq_subsample = np.count_nonzero(v.genotypes == allele)
#         freq_subsample.append(focal_freq_subsample)
# freq_subsample_segragate = [f for f in freq_subsample
#                             if (f != 0) & (f != sample_size)]

# TMRCA of all samples at the position of each mutation
# # t0 = time()
# t0 = time()
# tmrca_mut = []
# for p in pos_by_mut:
#     tmrca_mut.append(tree_height(mts.at(p), max_tick))
# timer = time() - t0
# print(timer)

# tmrca_mut = np.full(shape=mts.num_mutations,
#                     fill_value=np.nan)
# i = 0
# for p in pos_by_mut:
#     tmrca_mut[i] = tree_height(mts.at(p), max_tick)
#     i += 1

#### cor Freq-Env as a proximation of GEA
# Divide the population into 10x10 subpopulations, for each subpopulation,
# calculate the correlation between allele frequency of each mutation
# and average local environmental variable(optima)
# Assign a two-digit subpop id for each individual
# |90|91|92|93|94|95|96|97|98|99|
# ...
# |20|21|22|23|24|25|26|27|28|29|
# |10|11|12|03|14|15|16|17|18|19|
# |00|01|02|03|04|05|06|07|08|09|
map_width = 1.0
map_height = 1.0
# Only works when both num_row and num_col <= 10
num_row = 10
num_col = 10
num_sample_pop = num_row * num_col
sample_pop_ids = np.full(fill_value=np.nan,
                         shape=mts.num_individuals)
i = 0
for ind in mts.individuals():
    x = int(ind.location[0]/(map_width/num_row))
    y = int(ind.location[1]/(map_width/num_col))
    # Push the ones on the upper boundaries back
    x = x if x < num_row else (num_row-1)
    y = y if y < num_col else (num_col-1)
    sample_pop_ids[i] = x+y*10
    i += 1

np.unique(sample_pop_ids, return_counts=True)
# # Check the sample size of the grids
# plt.hist(sample_pop_ids, bins=100,
#          color="grey")
# plt.savefig(figPath+model_name+"_subsample_size.png",
#             dpi=300)
# plt.close()

# A collection of individual IDs for each subpopulation
inds_subpop = {}
# A collection of genome IDs for each subpopulation
genome_subpop = {}
# Average environmental optima of each sample population,
# calculated by the position of all local individuals
env_sample_pop = np.full(fill_value=np.nan,
                         shape=num_sample_pop)
# A vector of allele frequencies of all mutations for each sample population
freq_sample_pop = np.full(fill_value=np.nan,
                          shape=(mts.num_mutations, num_sample_pop))
for focal_pop_id in np.arange(num_sample_pop):
    focal_ind_list = np.array(np.where(sample_pop_ids == focal_pop_id)[0])
    focal_genome_list = np.stack((focal_ind_list*2,
                                  focal_ind_list*2+1)).ravel('F')
    inds_subpop[focal_pop_id] = focal_ind_list
    genome_subpop[focal_pop_id] = focal_genome_list
    # A special map: local env optima = x coordinates of local samples
    # env_sample_pop[focal_pop_id] = np.mean(mts.individuals_location[focal_ind_list][:, 0])
    #General form of optima
    env_sample_pop[focal_pop_id] = np.mean(optima[focal_ind_list])
    # Calculate derived allele frequency of each mutation in focal population
    index_site = 0
    index_mut = 0
    for v in mts.variants(samples=focal_genome_list):
        index_gt = 1
        # traverse all derived alleles at the site
        while index_gt < len(mut_effect_lists[index_site]):
            # if index_mut == 10000:
            #     test2 = v
            # print(v.genotypes)
            derived_freq = (np.count_nonzero(v.genotypes==index_gt)/
                            len(focal_genome_list))
            # print(len(focal_ind_list))
            # print(v.frequencies())
            # print(derived_freq)
            freq_sample_pop[index_mut][focal_pop_id] = derived_freq
            index_gt += 1
            index_mut += 1
        index_site += 1

# Correlation between allele frequency and environmental optima
# correlation coefficient and p-value
cor_GE = np.full(fill_value=np.nan,
                 shape=(4, mts.num_mutations))
for i in np.arange(mts.num_mutations):
    # skipped fixed/lost mutations
    if sum(freq_sample_pop[i]) > 0:
        # position 0: correlation coefficients, position 1: p-values
        # (cor_GE[0][i], cor_GE[1][i]) = stats.spearmanr(freq_sample_pop[i],
        #                                                env_sample_pop)
        (cor_GE[0][i], cor_GE[1][i]) = stats.kendalltau(freq_sample_pop[i],
                                                        env_sample_pop,
                                                      nan_policy="omit")
        (cor_GE[2][i], cor_GE[3][i]) = stats.pearsonr(freq_sample_pop[i],
                                                      env_sample_pop)

# # p-value adjusted by the Benjamini-Hochberg method
# # temporarily remove nan values
# p_mask = np.isnan(cor_GE[1])
# p_no_nan = cor_GE[1][~p_mask]
# p_BH_no_nan = stats.false_discovery_control(p_no_nan)
# p_BH = np.full(shape=len(cor_GE[1]), fill_value=np.nan)
# p_BH[~p_mask] = p_BH_no_nan

# # True positive rate, False negative rate, False discovery rate for all mutations
# # True adaptive allele: account for more than LF_min percent of positve LF_mut
# # GEA significant: BH-adjusted p-value < 0.05
# LF_positive = sum(delta_LF_mut[delta_LF_mut>0])
# LF_min = 0.01
# num_cat = 10
# cat_width = int(100/num_cat) if 100 % num_cat == 0 else 100/num_cat
# age_percentile = np.percentile(age,
#                                np.append(np.arange(0, 100, cat_width),100))
# TPR = []
# FPR = []
# FDR = []
# for i in range(num_cat):
#     # p_category = cor_GE[1][np.logical_and(age > age_percentile[i],
#     #                                   age <= age_percentile[i+1])]
#     p_BH_category = p_BH[np.logical_and(age > age_percentile[i],
#                                       age <= age_percentile[i+1])]
#     delta_LF_mut_category = delta_LF_mut[np.logical_and(age > age_percentile[i],
#                                       age <= age_percentile[i+1])]
#     # num_allele = len(p_BH_category)
#     # proportion_sig.append(sum(p_BH_category < 0.05)/num_allele)
#     expP = delta_LF_mut_category > LF_min*LF_positive
#     obsP = p_BH_category < 0.05
#     TP = sum(expP & obsP)
#     FP = sum(~expP & obsP)
#     FN = sum(expP & ~obsP)
#     TN = sum(~expP & ~obsP)
#     TPR.append(TP/(TP+FN))
#     FPR.append(FP/(TN+FP))
#     FDR.append(FP/(TP+FP))


# #### Separate neutral alleles: Skipped for single runs
# # mutation ID, allele age, allele frequency, mutation effect, LF_mut,
# # GEA Kendall's tau and corresponding p-value
# df = np.array([age,
#                freq,
#                mut_effect,
#                cor_GE[0],
#                cor_GE[1]])
# df_neutral = pandas.DataFrame(data=df.transpose(),
#                               columns=["age", "freq", "effect_size",
#                                        "tau", "p"])
# del df
# # Separate neutral alleles and remove lost or fixed alleles
# df_neutral = df_neutral[(df_neutral["effect_size"] == 0) &
#                         (df_neutral["freq"] != 0) &
#                         (df_neutral["freq"] != 1)]
# num_neutral_muts = df_neutral.shape[0]
#
#
# # False negative rate for NEUTRAL mutations among AGE categories
# # Equal numbers
# num_cat = 10
# cat_width = int(100/num_cat) if 100 % num_cat == 0 else 100/num_cat
# age_percentile = np.percentile(df_neutral["age"],
#                                np.append(np.arange(0, 100, cat_width),
#                                          100))
# FPR_neutral_byAge = []
# for i in range(num_cat):
#     p_category = df_neutral["p"][(df_neutral["age"] > age_percentile[i]) &
#                                  (df_neutral["age"] <= age_percentile[i+1])]
#     # Neutral mutations have no phenotypic effect and therefore no positive
#     mut_in_cat = len(p_category)
#     obsP_neutral = p_category < 0.05
#     # All positives are false positives
#     FP = sum(obsP_neutral)
#     FPR_neutral_byAge.append(FP/mut_in_cat)
#
# # False negative rate for NEUTRAL mutations among AGE categories
# # Equal width
# num_cat_age = 10
# max_age = ts.metadata['SLiM']['tick']
# cat_width_age = max_age/num_cat_age
# age_boundaries = np.append(np.arange(0, max_age, cat_width_age), max_age)
# FPR_neutral_byAge_equalWidth = []
# sample_size_age = []
# for i in range(num_cat_age):
#     p_category = df_neutral["p"][(df_neutral["age"] > age_boundaries[i]) &
#                                  (df_neutral["age"] <= age_boundaries[i+1])]
#     sample_size_age.append(len(p_category))
#     # Neutral mutations have no phenotypic effect and therefore no positive
#     mut_in_cat = len(p_category)
#     obsP_neutral = p_category < 0.05
#     # All positives are false positives
#     FP = sum(obsP_neutral)
#     FPR_neutral_byAge_equalWidth.append(FP/mut_in_cat)
#
# # False negative rate for NEUTRAL mutations among FREQUENCY categories
# # Equal numbers
# # Neutral mutations have no phenotypic effect and therefore no positve
# num_cat = 10
# cat_width = int(100/num_cat) if 100 % num_cat == 0 else 100/num_cat
# freq_percentile = np.percentile(df_neutral["freq"],
#                                np.append(np.arange(0, 100, cat_width),100))
# FPR_neutral_byFreq = []
# for i in range(num_cat):
#     if freq_percentile[i] != freq_percentile[i+1]:
#         p_category = df_neutral["p"][(df_neutral["freq"] > freq_percentile[i]) &
#                                      (df_neutral["freq"] <= freq_percentile[i+1])]
#     else:
#         # The frequency of singletons exceed bin width: Use the all singletons
#         p_category = df_neutral["p"][df_neutral["age"] == age_percentile[i]]
#     # Neutral mutations have no phenotypic effect and therefore no positive
#     mut_in_cat = len(p_category)
#     obsP_neutral = p_category < 0.05
#     # All positives are false positives
#     FP = sum(obsP_neutral)
#     FPR_neutral_byFreq.append(FP/mut_in_cat)
#
# # False negative rate for NEUTRAL mutations among FREQ categories
# # Equal intervals
# num_cat_freq = 10
# cat_width_freq = 1.0/num_cat_freq
# freq_boundaries = np.append(np.arange(0, 1.0, cat_width_freq), 1.0)
# FPR_neutral_byFreq_equalWidth = []
# sample_size_freq = []
# for i in range(num_cat_freq):
#     p_category = df_neutral["p"][(df_neutral["freq"] > freq_boundaries[i]) &
#                                  (df_neutral["freq"] <= freq_boundaries[i+1])]
#     sample_size_freq.append(len(p_category))
#     # Neutral mutations have no phenotypic effect and therefore no positive
#     mut_in_cat = len(p_category)
#     obsP_neutral = p_category < 0.05
#     # All positives are false positives
#     FP = sum(obsP_neutral)
#     FPR_neutral_byFreq_equalWidth.append(FP/mut_in_cat)


# # Fst: removed as it takes about 16Gb memory
# g = mts.genotype_matrix().reshape(mts.num_sites, mts.num_individuals, 2)
# subpops = [inds_subpop[i] for i in range(100)]
# a, b, c = allel.weir_cockerham_fst(g, subpops)
# fst_pop = a / (a + b + c)
# fst = np.sum(a) / (np.sum(a) + np.sum(b) + np.sum(c))
# print(fst)

#### Save the data table:
# mutation ID, allele age, allele frequency, mutation effect, LF_mut,
# GEA Kendall's tau and corresponding p-value
print("Saving the table...")
out_path_file = (outPath + model_name +
                 "_withNeutralMut_mutSeed" + str(mutation_seed) +
                 "_table.txt")
header = "\t".join(["pos", "age", "freq",
                    "mut_effect","mean_LF",
                    "tau","p-tau", "pearsonsrho", "p-rho"]) + "\n"
with open(out_path_file, "w") as fout:
    fout.write(header)
    for i in range(len(age)):
        words = [pos_by_mut[i],
                 age[i],
                 freq[i],
                 mut_effect[i],
                 mean_LF,
                 cor_GE[0][i],
                 cor_GE[1][i],
                 cor_GE[2][i],
                 cor_GE[3][i]]
        words = [str(i) for i in words]
        outLine = "\t".join(words) + "\n"
        fout.write(outLine)
print("The table has been saved.")

#### Plots ####
# # Skip the following lines and end the program if "--plot" is 0
if not bool(args.plot):
    print("Program finished. No plot will be generated as --plot is 0.")
    sys.exit(0)

#Path for the current run
# figPath = figPath + model_name + "_fst_" + str(round(fst,4)) +"/"
figPath = figPath + model_name
if not os.path.exists(figPath):
    os.mkdir(figPath)

# Display the average fitness of local and foreign populations
plt.figure(1)
plt.boxplot([w_local, w_foreign],
            labels=["Local", "Foreign"])
plt.xlabel("Groups")
plt.ylabel("Average relative fitness")
# plt.show()
plt.savefig(figPath + str(model_name) + "_test_localAdapt.png",
            dpi=300)
plt.close()

# Histogram of GEA p-values
plt.hist(cor_GE[1], bins=100,
         color="grey")
plt.xlabel("GEA p-values")
plt.ylabel("Count")
plt.savefig(figPath+model_name+"_GEA_pvalue_hist.png",
            dpi=300)
plt.close()

# Histogram of allele age
plt.hist(age, bins=100,
         color="grey")
plt.xlabel("Allele age")
plt.ylabel("Count")
plt.savefig(figPath+model_name+"_age_hist.png",
            dpi=300)
plt.close()

# Histogram of allele freq
plt.hist(freq, bins=100,
         color="grey")
plt.xlabel("Allele frequency")
plt.ylabel("Count")
plt.savefig(figPath+model_name+"_freq_hist.png",
            dpi=300)
plt.close()

# # Test: SFS of non-fixed/lost alleles in the subsample
# plt.hist(freq_subsample_segragate, bins=100,
#          color="grey")
# plt.xlabel("Allele frequency")
# plt.ylabel("Count")
# plt.savefig(figPath+model_name+"_freq_hist_" + str(sample_size) + "samples.png",
#             dpi=300)
# plt.close()

# # Histogram of allele age of neutral alleles
# plt.hist(df_neutral["age"], bins=100,
#          color="grey")
# plt.xlabel("Allele age")
# plt.ylabel("Count")
# plt.savefig(figPath+model_name+"_age_hist_neutral.png",
#             dpi=300)
# plt.close()
#
# # Histogram of allele freq of neutral alleles
# plt.hist(df_neutral["freq"], bins=100,
#          color="grey")
# plt.xlabel("Allele frequency")
# plt.ylabel("Count")
# plt.savefig(figPath+model_name+"_freq_hist_neutral.png",
#             dpi=300)
# plt.close()
#
# # Histogram of raw GEA p-values by allele age
# # Also calculate the proportion of significant (FDR < 0.05) alleles in each age category,
# # using p-values adjusted with Benjamini-Hochberg method
# num_cat = 10
# age_percentile = np.percentile(age, np.append(np.arange(0, 100, num_cat),100))
# # k = 0
# proportion_sig = []
# for i in range(num_cat):
#     # k += len(cor_GE[1][np.logical_and(age > age_percentile[i],
#     #                                   age <= age_percentile[i+1])])
#     p_category = cor_GE[1][np.logical_and(age > age_percentile[i],
#                                       age <= age_percentile[i+1])]
#     p_BH_category = p_BH[np.logical_and(age > age_percentile[i],
#                                       age <= age_percentile[i+1])]
#     num_allele = len(p_category)
#     # proportion_sig.append(sum(p_BH_category < 0.05)/num_allele)
#     proportion_sig.append(sum(p_category < 0.05) / num_allele)
#     plt.hist(p_category,
#              bins=100,
#              color="grey")
#     plt.xlabel("GEA p-values")
#     plt.ylabel("Count")
#
#     plt.title("Bin " + str(i) + ": \n " +
#               "age " +str(int(age_percentile[i])) +
#               "-" + str(int(age_percentile[i+1])))
#     plt.savefig(figPath+model_name+"_GEA_pvalue_hist_byAge_bin"+str(i)+".png",
#                 dpi=300)
#     plt.close()
# # print(k)
#
# # Proportion of significant alleles ~ age percentile bin
# num_cat = 10
# plt.plot(np.arange(100/num_cat, 110, 100/num_cat),
#          proportion_sig,
#          color="grey")
# plt.xlabel("Allele age percentile bins")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("Proportion of alleles with p-value < 0.05")
# plt.xticks(ticks=np.arange(100/num_cat, 110, 100/num_cat),
#            labels=[(str(i*10)+"-"+str(i*10+10)) for i in range(10)])
# plt.savefig(figPath+model_name+"_proportionGEArawP_vs_age.png",
#             dpi=300)
# plt.close()
#

# # Histogram of GEA tau
# plt.hist(cor_GE[0], bins=100,
#          color="grey")
# plt.xlabel("GEA Kendall's tau")
# plt.ylabel("Count")
# plt.savefig(figPath+model_name+"_GEA_tau_hist.png",
#             dpi=300)
# plt.close()

# # GEA p-value ~ Allele age
# plt.scatter(age, cor_GE[1],
#          marker="o",
#          c="grey", alpha=0.05)
# plt.xlabel("Allele age")
# plt.ylabel("GEA p-values")
# # plt.colorbar().set_label("$LF_{mut}$")
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_GEApvalue_vs_age.png",
#             dpi=300)
# plt.close()

# # |GEA Kendall's tau| ~ Allele age
# plt.scatter(age, abs(cor_GE[0]),
#          marker="o",
#          c="grey", alpha=0.05)
# plt.xlabel("Allele age")
# plt.ylabel("|GEA Kendall's tau|")
# # plt.colorbar().set_label("$LF_{mut}$")
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_absGEATau_vs_age.png",
#             dpi=300)
# plt.close()

# # Allele frequency ~ Allele age
# plt.scatter(age, freq,
#          marker="o",
#          # c=cor_GE[1], alpha=0.05)
#          c="grey", alpha = 0.05)
# plt.xlabel("Allele age")
# plt.ylabel("Allele frequency")
# # plt.colorbar().set_label("GEA p-values")
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_freq_vs_age.png",
#             dpi=300)
# plt.close()

# # FPR ～ Allele age
# plt.plot(np.arange(100/num_cat, 101, 100/num_cat),
#          FPR,
#          color="grey")
# plt.xlabel("Allele age percentile bins")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate (FP/(FP+TN)))")
# plt.xticks(ticks=np.arange(100/num_cat, 101, 100/num_cat),
#            labels=[(str(i*cat_width)+"-"+str((i+1)*cat_width))
#                    for i in range(num_cat)])
# # plt.savefig(figPath+model_name+"_proportionGEABHp_vs_age.png",
# #             dpi=300)
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_lfmut1percent_GEABHp0.05_vs_age.png",
#             dpi=300)
# plt.close()

# # Neutral alleles: FPR ～ Allele age, equal number alleles per bin
# num_cat = 10
# bin_width = 100/num_cat
# plt.plot(np.arange(100/num_cat, 101, 100/num_cat) + 0.5*bin_width,
#          FPR_neutral_byAge,
#          color="grey",
#          marker = "o")
# plt.xlabel("\n\nAllele age percentile bins")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate of neutral alleles (FP/(FP+TN))")
# for i in range(num_cat + 1):
#     label = str(int(age_percentile[i]))
#     x = np.arange(100/num_cat, 101+bin_width, 100/num_cat)[i]
#     y = -0.1 * max(FPR_neutral_byAge)
#     # if i != 0:
#     #     y = (FPR_neutral_byFreq[i] + FPR_neutral_byFreq[i-1])/2
#     # else:
#     #     y = FPR_neutral_byFreq[i] / 2
#     plt.annotate(label,
#                  (x,y),
#                  textcoords="offset points",
#                  xytext=(-0.5*bin_width, -0.5*bin_width),
#                  annotation_clip=False,
#                  color="grey")
#     plt.xticks([], minor=False)
# plt.xticks(ticks=np.arange(100/num_cat, 111, 100/num_cat),
#            labels=[str(int(i*cat_width)) for i in range(num_cat+1)])
# # plt.savefig(figPath+model_name+"_proportionGEABHp_vs_age.png",
# #             dpi=300)
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_GEAp0.05_vs_age_neutralAllele.png",
#             dpi=300)
# plt.close()
#
# # Neutral alleles: FPR ～ Frequency, equal number alleles per bin
# num_cat = 10
# bin_width = 100/num_cat
# plt_pos = np.arange(100/num_cat, 101, 100/num_cat) - 5
# plt.plot(plt_pos,
#          FPR_neutral_byFreq,
#          color="grey",
#          marker = "o")
# plt.xlabel("\n\n\nAllele frequency percentile bins")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate of neutral alleles (FP/(FP+TN))")
# for i in range(num_cat + 1):
#     label = "{:.5f}".format(freq_percentile[i])
#     print(label)
#     x = np.arange(0, 101+bin_width, 100/num_cat)[i]
#     y = -0.22
#     plt.annotate(label,
#                  (x,y),
#                  textcoords="offset points",
#                  xytext=(-1*bin_width, 0.5*bin_width),
#                  annotation_clip=False,
#                  color="grey",
#                  rotation = 45)
#     plt.xticks([], minor=False)
# plt.xticks(ticks=np.arange(0, 101, 100/num_cat),
#            labels=[str(int(i*cat_width)) for i in range(num_cat+1)])
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_GEAp0.05_vs_freq_neutralAllele.png",
#             dpi=300)
# plt.close()
#
# # Neutral alleles: FPR ～ Allele age, equal intervals
# plt.plot(age_boundaries[0:-1] + cat_width_age/2,
#          FPR_neutral_byAge_equalWidth,
#          color="grey",
#          marker = "o")
# plt.xlabel("Allele age")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate of neutral alleles (FP/(FP+TN))")
# plt.xticks(ticks=age_boundaries,
#            labels=[str(int(i)) for i in age_boundaries])
# # plt.savefig(figPath+model_name+"_proportionGEABHp_vs_age.png",
# #             dpi=300)
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_GEAp0.05_vs_age_neutralAllele_equalInterval.png",
#             dpi=300)
# plt.close()
#
# # Neutral alleles: FPR ～ Allele frequency, equal intervals
# plt.plot(freq_boundaries[0:-1] + cat_width_freq/2,
#          FPR_neutral_byFreq_equalWidth,
#          color="grey",
#          marker = "o")
# plt.xlabel("Allele frequency")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate of neutral alleles (FP/(FP+TN))")
# plt.xticks(ticks=freq_boundaries,
#            labels=[str(round(i,2)) for i in freq_boundaries])
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_GEAp0.05_vs_freq_neutralAllele_equalInterval.png",
#             dpi=300)
# plt.close()
#
# # Neutral alleles: FPR ～ Freq, equal intervals
# plt.plot(freq_boundaries[0:-1] + cat_width_freq/2,
#          FPR_neutral_byFreq_equalWidth,
#          color="grey",
#          marker = "o")
# plt.xlabel("Allele frequency")
# # plt.ylabel("Proportion of alleles with BH-adjusted p-value < 0.05")
# plt.ylabel("False positive rate of neutral alleles (FP/(FP+TN))")
# plt.xticks(ticks=freq_boundaries,
#            labels=[str(i) for i in freq_boundaries])
# plt.tight_layout()
# plt.savefig(figPath+model_name+"_"+
#             str(num_cat)+"bins"+"_FPR_GEAp0.05_vs_freq_neutralAllele_equalInterval.png",
#             dpi=300)
# plt.close()


